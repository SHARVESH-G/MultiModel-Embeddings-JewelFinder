{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6dem2scdEhd6",
        "outputId": "b65d1188-f5e7-48c4-9310-ca311991b458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git qdrant-client pytesseract gradio opencv-python pillow scikit-learn symspellpy openai -q\n",
        "!apt-get install tesseract-ocr -qq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git qdrant-client pytesseract gradio opencv-python pillow scikit-learn symspellpy openai -q\n",
        "!apt-get install tesseract-ocr -qq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, uuid, cv2, torch, clip, numpy as np\n",
        "import pytesseract\n",
        "import gradio as gr\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
        "\n",
        "import pkg_resources\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… OpenAI connected\n"
          ]
        }
      ],
      "source": [
        "API_KEY = userdata.get(\"API_KEY\")\n",
        "BASE_URL = userdata.get(\"BASE_URL\")\n",
        "\n",
        "ai_client = OpenAI(api_key=API_KEY, base_url=BASE_URL) if BASE_URL else OpenAI(api_key=API_KEY)\n",
        "\n",
        "print(\"âœ… OpenAI connected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLIP running on: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "\n",
        "print(\"CLIP running on:\", device)\n",
        "\n",
        "qdrant_client = QdrantClient(\":memory:\")\n",
        "DIM = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
        "\n",
        "def clean_query(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.lower().strip()\n",
        "    suggestion = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    return suggestion[0].term if suggestion else text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ring_gold â†’ 52\n",
            "ring_silver â†’ 17\n",
            "ring_copper â†’ 4\n",
            "necklace_gold â†’ 9\n",
            "necklace_silver â†’ 0\n",
            "necklace_copper â†’ 0\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = \"/content/drive/MyDrive/clustered_images\"\n",
        "\n",
        "clusters = {}\n",
        "\n",
        "for item_type in os.listdir(DATA_ROOT):\n",
        "    type_path = os.path.join(DATA_ROOT, item_type)\n",
        "    if not os.path.isdir(type_path):\n",
        "        continue\n",
        "\n",
        "    for metal in os.listdir(type_path):\n",
        "        metal_path = os.path.join(type_path, metal)\n",
        "        if not os.path.isdir(metal_path):\n",
        "            continue\n",
        "\n",
        "        name = f\"{item_type}_{metal}\"\n",
        "\n",
        "        images = [\n",
        "            os.path.join(metal_path, f)\n",
        "            for f in os.listdir(metal_path)\n",
        "            if f.lower().endswith((\".jpg\",\".png\",\".jpeg\",\".webp\"))\n",
        "        ]\n",
        "\n",
        "        clusters[name] = images\n",
        "\n",
        "for k,v in clusters.items():\n",
        "    print(k, \"â†’\", len(v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_image_emb(path):\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = clip_model.encode_image(image_input)\n",
        "\n",
        "    return (emb / emb.norm(dim=-1, keepdim=True))[0]\n",
        "\n",
        "def get_text_emb(text):\n",
        "    tokens = clip.tokenize([text]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = clip_model.encode_text(tokens)\n",
        "\n",
        "    return (emb / emb.norm(dim=-1, keepdim=True))[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ocr_text(path):\n",
        "    try:\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            return \"\"\n",
        "        return pytesseract.image_to_string(img).strip()\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def fuse_emb(img_emb, txt_emb, alpha=0.7):\n",
        "    fused = alpha * img_emb + (1 - alpha) * txt_emb\n",
        "    return fused / fused.norm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1336531758.py:5: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Indexed ring_gold: 52 images\n",
            "âœ… Indexed ring_silver: 17 images\n",
            "âœ… Indexed ring_copper: 4 images\n",
            "âœ… Indexed necklace_gold: 9 images\n",
            "âœ… Indexed necklace_silver: 0 images\n",
            "âœ… Indexed necklace_copper: 0 images\n"
          ]
        }
      ],
      "source": [
        "def index_drive():\n",
        "\n",
        "    for cluster_name, images in clusters.items():\n",
        "\n",
        "        qdrant_client.recreate_collection(\n",
        "            collection_name=cluster_name,\n",
        "            vectors_config=VectorParams(size=DIM, distance=Distance.COSINE)\n",
        "        )\n",
        "\n",
        "        points = []\n",
        "\n",
        "        for path in images:\n",
        "            emb = get_image_emb(path)\n",
        "\n",
        "            points.append(\n",
        "                PointStruct(\n",
        "                    id=str(uuid.uuid4()),\n",
        "                    vector=emb.cpu().numpy().tolist(),\n",
        "                    payload={\"path\": path}\n",
        "                )\n",
        "            )\n",
        "\n",
        "        qdrant_client.upsert(collection_name=cluster_name, points=points)\n",
        "\n",
        "        print(f\"âœ… Indexed {cluster_name}: {len(points)} images\")\n",
        "\n",
        "index_drive()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "METALS = [\"gold\", \"silver\", \"copper\"]\n",
        "TYPES = [\"ring\", \"necklace\"]\n",
        "\n",
        "def route_metal(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for m in METALS:\n",
        "        if m in text:\n",
        "            return m\n",
        "    return None\n",
        "\n",
        "def route_type(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for t in TYPES:\n",
        "        if t in text:\n",
        "            return t\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GEMS = [\"ruby\", \"diamond\", \"emerald\", \"sapphire\"]\n",
        "\n",
        "def route_gem(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for g in GEMS:\n",
        "        if g in text:\n",
        "            return g\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_all(emb, metal=None, item_type=None, topk=20):\n",
        "\n",
        "    hits_all = []\n",
        "\n",
        "    for collection in qdrant_client.get_collections().collections:\n",
        "\n",
        "        name = collection.name\n",
        "\n",
        "        if metal and metal not in name:\n",
        "            continue\n",
        "\n",
        "        if item_type and item_type not in name:\n",
        "            continue\n",
        "\n",
        "        hits = qdrant_client.query_points(\n",
        "            collection_name=name,\n",
        "            query=emb.cpu().numpy().tolist(),\n",
        "            limit=topk,\n",
        "            with_vectors=True\n",
        "        )\n",
        "\n",
        "        hits_all.extend(hits.points)\n",
        "\n",
        "    return hits_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_gem_color(path):\n",
        "\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        return \"unknown\"\n",
        "\n",
        "    img = cv2.resize(img, (200, 200))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # detect white (diamond)\n",
        "    white_mask = cv2.inRange(hsv, (0, 0, 200), (180, 40, 255))\n",
        "    white_ratio = np.sum(white_mask > 0) / white_mask.size\n",
        "\n",
        "    # if mostly white â†’ diamond\n",
        "    if white_ratio > 0.12:\n",
        "        return \"diamond\"\n",
        "\n",
        "    # otherwise any colored stone â†’ ruby\n",
        "    return \"ruby\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_query(text=None, image_path=None):\n",
        "\n",
        "    text = clean_query(text)\n",
        "\n",
        "    if text and not image_path:\n",
        "        emb = get_text_emb(text)\n",
        "\n",
        "    elif image_path and not text:\n",
        "        emb = get_image_emb(image_path)\n",
        "\n",
        "    else:\n",
        "        ocr = ocr_text(image_path) if not text or len(text) < 3 else \"\"\n",
        "        combined = (text or \"\") + \" \" + ocr\n",
        "\n",
        "        img_emb = get_image_emb(image_path)\n",
        "        txt_emb = get_text_emb(combined)\n",
        "        emb = fuse_emb(img_emb, txt_emb)\n",
        "\n",
        "    metal = route_metal(text)\n",
        "    item_type = route_type(text)\n",
        "    gem = route_gem(text)\n",
        "\n",
        "    hits = search_all(emb, metal, item_type)\n",
        "\n",
        "    if not hits:\n",
        "        return [], \"âŒ Requested product not available sir ðŸ˜”\"\n",
        "\n",
        "    strict_bucket = []\n",
        "    fallback_bucket = []\n",
        "\n",
        "    query_vec = emb.cpu().numpy()\n",
        "\n",
        "    for h in hits:\n",
        "\n",
        "        path = h.payload[\"path\"]\n",
        "        detected = detect_gem_color(path)\n",
        "\n",
        "        vec = np.array(h.vector)\n",
        "        score = cosine_similarity([query_vec], [vec])[0][0]\n",
        "\n",
        "        if gem and detected == gem:\n",
        "            strict_bucket.append((score, path))\n",
        "        else:\n",
        "            fallback_bucket.append((score, path))\n",
        "\n",
        "    # sort buckets\n",
        "    strict_bucket.sort(reverse=True)\n",
        "    fallback_bucket.sort(reverse=True)\n",
        "\n",
        "    # ðŸ”¥ fallback protection\n",
        "    if strict_bucket:\n",
        "        scored = strict_bucket + fallback_bucket\n",
        "    else:\n",
        "        scored = fallback_bucket   # never return empty\n",
        "\n",
        "    top = scored[:6]\n",
        "\n",
        "    results = [p for _, p in top]\n",
        "    score = top[0][0]\n",
        "\n",
        "    review = salesman_review_ai(results[0], text)\n",
        "    review += f\"\\n\\nMatch score: {score:.2f}\"\n",
        "\n",
        "    return results, review\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def salesman_review_ai(path, query_text):\n",
        "\n",
        "    parts = path.split(os.sep)\n",
        "    metal = parts[-2]\n",
        "    item_type = parts[-3]\n",
        "\n",
        "    query_text = query_text if query_text else \"image reference\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a charming Tamil jewelry salesman.\n",
        "\n",
        "Customer request: {query_text}\n",
        "Matched item: {metal} {item_type}\n",
        "\n",
        "Speak in natural Tanglish.\n",
        "Use 3â€“4 bullet points.\n",
        "Mention style, premium feel, occasion.\n",
        "Friendly tone.\n",
        "\"\"\"\n",
        "\n",
        "    r = ai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-nano\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}]\n",
        "    )\n",
        "\n",
        "    return r.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dd4a0b33677c2e9f5d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://dd4a0b33677c2e9f5d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def gradio_search(text, image):\n",
        "    image_path = image if image else None\n",
        "    results, review = run_query(text, image_path)\n",
        "    return results, review\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_search,\n",
        "    inputs=[gr.Textbox(), gr.File(type=\"filepath\")],\n",
        "    outputs=[gr.Gallery(), gr.Textbox()],\n",
        "    title=\"ðŸ’Ž AI Jewelry Search\"\n",
        ")\n",
        "\n",
        "demo.queue(False)\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWTqiMtOEjxV",
        "outputId": "cbbfe21d-c386-4076-aa31-51912c89e394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1CkCMN-GEoKC"
      },
      "outputs": [],
      "source": [
        "import os, uuid, cv2, torch, clip, numpy as np\n",
        "import pytesseract\n",
        "import gradio as gr\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
        "\n",
        "from symspellpy import SymSpell\n",
        "import pkg_resources\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVvmbUC2Evcx",
        "outputId": "0e149261-0cd1-438e-8e69-b8948eed8463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… OpenAI connected\n"
          ]
        }
      ],
      "source": [
        "API_KEY = userdata.get(\"API_KEY\")\n",
        "BASE_URL = userdata.get(\"BASE_URL\")\n",
        "\n",
        "ai_client = OpenAI(api_key=API_KEY, base_url=BASE_URL) if BASE_URL else OpenAI(api_key=API_KEY)\n",
        "\n",
        "print(\"âœ… OpenAI connected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtk55i3fE38l",
        "outputId": "0b10b935-c468-4a4a-cb5a-265a9c9544a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLIP running on: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval()\n",
        "\n",
        "print(\"CLIP running on:\", device)\n",
        "\n",
        "qdrant_client = QdrantClient(\":memory:\")\n",
        "DIM = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CBT0kegSE8dU"
      },
      "outputs": [],
      "source": [
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "sym_spell.load_dictionary(dictionary_path, 0, 1)\n",
        "\n",
        "def clean_query(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.lower().strip()\n",
        "    suggestion = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    return suggestion[0].term if suggestion else text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn56KWLEFAt7",
        "outputId": "73dc35a4-bd04-422b-947a-cb46dc099579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ring_gold â†’ 52\n",
            "ring_silver â†’ 17\n",
            "ring_copper â†’ 4\n",
            "necklace_gold â†’ 9\n",
            "necklace_silver â†’ 0\n",
            "necklace_copper â†’ 0\n"
          ]
        }
      ],
      "source": [
        "DATA_ROOT = \"/content/drive/MyDrive/clustered_images\"\n",
        "\n",
        "clusters = {}\n",
        "\n",
        "for item_type in os.listdir(DATA_ROOT):\n",
        "    type_path = os.path.join(DATA_ROOT, item_type)\n",
        "    if not os.path.isdir(type_path):\n",
        "        continue\n",
        "\n",
        "    for metal in os.listdir(type_path):\n",
        "        metal_path = os.path.join(type_path, metal)\n",
        "        if not os.path.isdir(metal_path):\n",
        "            continue\n",
        "\n",
        "        name = f\"{item_type}_{metal}\"\n",
        "\n",
        "        images = [\n",
        "            os.path.join(metal_path, f)\n",
        "            for f in os.listdir(metal_path)\n",
        "            if f.lower().endswith((\".jpg\",\".png\",\".jpeg\",\".webp\"))\n",
        "        ]\n",
        "\n",
        "        clusters[name] = images\n",
        "\n",
        "for k,v in clusters.items():\n",
        "    print(k, \"â†’\", len(v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HTjqPY0cFFmZ"
      },
      "outputs": [],
      "source": [
        "def get_image_emb(path):\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = clip_model.encode_image(image_input)\n",
        "\n",
        "    return (emb / emb.norm(dim=-1, keepdim=True))[0]\n",
        "\n",
        "def get_text_emb(text):\n",
        "    tokens = clip.tokenize([text]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = clip_model.encode_text(tokens)\n",
        "\n",
        "    return (emb / emb.norm(dim=-1, keepdim=True))[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LNlBiAHUFIGe"
      },
      "outputs": [],
      "source": [
        "def ocr_text(path):\n",
        "    try:\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            return \"\"\n",
        "        return pytesseract.image_to_string(img).strip()\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def fuse_emb(img_emb, txt_emb, alpha=0.7):\n",
        "    fused = alpha * img_emb + (1 - alpha) * txt_emb\n",
        "    return fused / fused.norm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL5dT04NFL36",
        "outputId": "207d3ec0-f165-4e9d-da63-4db484ddca80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1336531758.py:5: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Indexed ring_gold: 52 images\n",
            "âœ… Indexed ring_silver: 17 images\n",
            "âœ… Indexed ring_copper: 4 images\n",
            "âœ… Indexed necklace_gold: 9 images\n",
            "âœ… Indexed necklace_silver: 0 images\n",
            "âœ… Indexed necklace_copper: 0 images\n"
          ]
        }
      ],
      "source": [
        "def index_drive():\n",
        "\n",
        "    for cluster_name, images in clusters.items():\n",
        "\n",
        "        qdrant_client.recreate_collection(\n",
        "            collection_name=cluster_name,\n",
        "            vectors_config=VectorParams(size=DIM, distance=Distance.COSINE)\n",
        "        )\n",
        "\n",
        "        points = []\n",
        "\n",
        "        for path in images:\n",
        "            emb = get_image_emb(path)\n",
        "\n",
        "            points.append(\n",
        "                PointStruct(\n",
        "                    id=str(uuid.uuid4()),\n",
        "                    vector=emb.cpu().numpy().tolist(),\n",
        "                    payload={\"path\": path}\n",
        "                )\n",
        "            )\n",
        "\n",
        "        qdrant_client.upsert(collection_name=cluster_name, points=points)\n",
        "\n",
        "        print(f\"âœ… Indexed {cluster_name}: {len(points)} images\")\n",
        "\n",
        "index_drive()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7g2z03lMFQWJ"
      },
      "outputs": [],
      "source": [
        "METALS = [\"gold\", \"silver\", \"copper\"]\n",
        "TYPES = [\"ring\", \"necklace\"]\n",
        "\n",
        "def route_metal(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for m in METALS:\n",
        "        if m in text:\n",
        "            return m\n",
        "    return None\n",
        "\n",
        "def route_type(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for t in TYPES:\n",
        "        if t in text:\n",
        "            return t\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dFmQfA2nlGvE"
      },
      "outputs": [],
      "source": [
        "GEMS = [\"ruby\", \"diamond\", \"emerald\", \"sapphire\"]\n",
        "\n",
        "def route_gem(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for g in GEMS:\n",
        "        if g in text:\n",
        "            return g\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "LORYVpPZFYTZ"
      },
      "outputs": [],
      "source": [
        "def search_all(emb, metal=None, item_type=None, topk=20):\n",
        "\n",
        "    hits_all = []\n",
        "\n",
        "    for collection in qdrant_client.get_collections().collections:\n",
        "\n",
        "        name = collection.name\n",
        "\n",
        "        if metal and metal not in name:\n",
        "            continue\n",
        "\n",
        "        if item_type and item_type not in name:\n",
        "            continue\n",
        "\n",
        "        hits = qdrant_client.query_points(\n",
        "            collection_name=name,\n",
        "            query=emb.cpu().numpy().tolist(),\n",
        "            limit=topk,\n",
        "            with_vectors=True\n",
        "        )\n",
        "\n",
        "        hits_all.extend(hits.points)\n",
        "\n",
        "    return hits_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "aOpJvnfopzrQ"
      },
      "outputs": [],
      "source": [
        "def detect_gem_color(path):\n",
        "\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        return \"unknown\"\n",
        "\n",
        "    img = cv2.resize(img, (200, 200))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # detect white (diamond)\n",
        "    white_mask = cv2.inRange(hsv, (0, 0, 200), (180, 40, 255))\n",
        "    white_ratio = np.sum(white_mask > 0) / white_mask.size\n",
        "\n",
        "    # if mostly white â†’ diamond\n",
        "    if white_ratio > 0.12:\n",
        "        return \"diamond\"\n",
        "\n",
        "    # otherwise any colored stone â†’ ruby\n",
        "    return \"ruby\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "50y4fHIRFbSg"
      },
      "outputs": [],
      "source": [
        "def run_query(text=None, image_path=None):\n",
        "\n",
        "    text = clean_query(text)\n",
        "\n",
        "    if text and not image_path:\n",
        "        emb = get_text_emb(text)\n",
        "\n",
        "    elif image_path and not text:\n",
        "        emb = get_image_emb(image_path)\n",
        "\n",
        "    else:\n",
        "        ocr = ocr_text(image_path) if not text or len(text) < 3 else \"\"\n",
        "        combined = (text or \"\") + \" \" + ocr\n",
        "\n",
        "        img_emb = get_image_emb(image_path)\n",
        "        txt_emb = get_text_emb(combined)\n",
        "        emb = fuse_emb(img_emb, txt_emb)\n",
        "\n",
        "    metal = route_metal(text)\n",
        "    item_type = route_type(text)\n",
        "    gem = route_gem(text)\n",
        "\n",
        "    hits = search_all(emb, metal, item_type)\n",
        "\n",
        "    if not hits:\n",
        "        return [], \"âŒ Requested product not available sir ðŸ˜”\"\n",
        "\n",
        "    strict_bucket = []\n",
        "    fallback_bucket = []\n",
        "\n",
        "    query_vec = emb.cpu().numpy()\n",
        "\n",
        "    for h in hits:\n",
        "\n",
        "        path = h.payload[\"path\"]\n",
        "        detected = detect_gem_color(path)\n",
        "\n",
        "        vec = np.array(h.vector)\n",
        "        score = cosine_similarity([query_vec], [vec])[0][0]\n",
        "\n",
        "        if gem and detected == gem:\n",
        "            strict_bucket.append((score, path))\n",
        "        else:\n",
        "            fallback_bucket.append((score, path))\n",
        "\n",
        "    # sort buckets\n",
        "    strict_bucket.sort(reverse=True)\n",
        "    fallback_bucket.sort(reverse=True)\n",
        "\n",
        "    # ðŸ”¥ fallback protection\n",
        "    if strict_bucket:\n",
        "        scored = strict_bucket + fallback_bucket\n",
        "    else:\n",
        "        scored = fallback_bucket   # never return empty\n",
        "\n",
        "    top = scored[:6]\n",
        "\n",
        "    results = [p for _, p in top]\n",
        "    score = top[0][0]\n",
        "\n",
        "    review = salesman_review_ai(results[0], text)\n",
        "    review += f\"\\n\\nMatch score: {score:.2f}\"\n",
        "\n",
        "    return results, review\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "CjH1MAm4jf1l"
      },
      "outputs": [],
      "source": [
        "def salesman_review_ai(path, query_text):\n",
        "\n",
        "    parts = path.split(os.sep)\n",
        "    metal = parts[-2]\n",
        "    item_type = parts[-3]\n",
        "\n",
        "    query_text = query_text if query_text else \"image reference\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a charming Tamil jewelry salesman.\n",
        "\n",
        "Customer request: {query_text}\n",
        "Matched item: {metal} {item_type}\n",
        "\n",
        "Speak in natural Tanglish.\n",
        "Use 3â€“4 bullet points.\n",
        "Mention style, premium feel, occasion.\n",
        "Friendly tone.\n",
        "\"\"\"\n",
        "\n",
        "    r = ai_client.chat.completions.create(\n",
        "        model=\"gpt-4.1-nano\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}]\n",
        "    )\n",
        "\n",
        "    return r.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "F-Dp54uXjg1g",
        "outputId": "c60155d6-60ac-4e3a-e1ce-c8f0b4dbbde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dd4a0b33677c2e9f5d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://dd4a0b33677c2e9f5d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gradio_search(text, image):\n",
        "    image_path = image if image else None\n",
        "    results, review = run_query(text, image_path)\n",
        "    return results, review\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_search,\n",
        "    inputs=[gr.Textbox(), gr.File(type=\"filepath\")],\n",
        "    outputs=[gr.Gallery(), gr.Textbox()],\n",
        "    title=\"ðŸ’Ž AI Jewelry Search\"\n",
        ")\n",
        "\n",
        "demo.queue(False)\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
